{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 7: CNN Architectures and RNNs\n",
    "\n",
    "In this lesson, we will use what we’ve learned so far in the course to explore other CNN architectures and how they can be used to enter the [Nature Conservancy Fisheries Monitoring Kaggle Competition](https://www.kaggle.com/c/the-nature-conservancy-fisheries-monitoring). The pre-trained convolutional layers will not be altered in the neural networks used for this lesson. So, the training data will simply be the output of the convolutional layers. Then, we’ll review our discussion of backpropagation by building a simple RNN in python and a more complex RNN known as the GRU.  \n",
    "\n",
    "The first CNN architecture we’ll cover is ResNet50.\n",
    "\n",
    "## ResNet50\n",
    "\n",
    "We know CNNs are stacked layers of linear and non-linear operations that are trained to identify features from given inputs to generate predicted outputs. The deeper the network, the more difficult it is to train and the greater the issue of exploding gradients becomes. This is addressed through the addition of normalization layers, where networks with tens of thousands of layers can converge through SGD with backpropagation. Once the layers converge, the issue of **degradation** arises, where accuracy is easily oversaturated before it rapidly degrades. This degradation is not caused by overfitting and adding more layers to an already deep model leads to higher training errors.\n",
    "\n",
    "**Residual learning** attempts to solve these issues by directly connecting input from the $n$th layer to some $n+i$th layer using the identity function, $id(x) = x$. These identity connections enable the layers to learn incremental, or residual, features. In the image below, taken from Microsoft Research's paper on [Deep Residual Learning for Image Recognition](https://arxiv.org/pdf/1512.03385.pdf), $F(x)$ is the learned residual mapping of (possibly) multiple convolutional layers. The operation $F(x) + x$ is performed using a shortcut connection and element-wise addition that is formulated through the feedforward neural networks (skipping one or more layers). These shortcut connections simply perform identity mappings and don't add to the computational complexity of the model.   \n",
    "\n",
    "![img](https://i.imgur.com/QPUe5lB.png[/img])\n",
    "\n",
    "So, how does residual learning compare to VGG? The networks are similar in that they use 3x3 convolutions, activation layers, and max pooling. When using VGG, our output $y = c(c(c(x)))$ is a convolution of a convolution of a convolution of some input $x$. However, for ResNet, these convolutions of convolutions of convolutions are what make up an identity block, sequentially indexed in steps of time $t$. The hidden layer at time $t$ then becomes $h(t+1) = c(c(c(h(t)))) + h(t)$. \n",
    "\n",
    "All of the layers of the ResNet architecture are built so that they gradually improve by modeling how each layer differs from the next, a method also known as **boosting**. Dimensionality here remains constant. To build deeper networks, the weights applied to each layer are backpropagated through an indentity without having to worry about exploding gradients. The hidden layer $h(t)$ can then be subtracted to get the residual. This leaves us with the convolution of the convolution of the convolution of $h(t)$. \n",
    "\n",
    "We will now add **ResNet50** to our cats vs. dogs image classification model, which is a 50 layer residual network. We’ll be using the network for image classification the same way we’ve used VGG16 in previous lessons. There are other variants of the network, like ResNet101 and ResNet152, that we will not discuss in this lesson. \n",
    "\n",
    "Let's start by importing all necessary modules and creating our ResNet50 model object..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "from __future__ import division, print_function\n",
    "import resnet50; reload(resnet50)\n",
    "from resnet50 import Resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rn0 = Resnet50(include_top=False).model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `include_top=False` parameter ensures that only the convolutional layers are included in the model, which gives us the freedom to attach our own classification layers afterwards. We can see that this is accounted for in a snippet from the `create` function below:\n",
    "\n",
    "```python\n",
    "if include_top:\n",
    "    x = AveragePooling2d((7,7), name='avg_pool')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1000, activation='softmax', name='fc1000')(x)\n",
    "    name = 'rn50.h5'\n",
    "else:\n",
    "    name = 'resnet_nt.h5'\n",
    "```\n",
    "\n",
    "We can now get our batches and precompute the convolutional features: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = 'data/dogscats/'\n",
    "batch_size = 64\n",
    "model_path = 'data/dogscats/models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n",
      "Found 23000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "batches = get_batches(path+'train', shuffle=False, batch_size=batch_size)\n",
    "val_batches = get_batches(path+'valid', batch_size=batch_size*2, shuffle=False)\n",
    "(val_classes, trn_classes, val_labels, trn_labels, val_filenames, filenames, test_filenames) = get_classes(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_features = rn0.predict_generator(val_batches, val_batches.nb_sample)\n",
    "trn_features = rn0.predict_generator(batches, batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array(model_path + 'trn_rn0_conv.bc', trn_features)\n",
    "save_array(model_path + 'val_rn0_conv.bc', val_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now stick our layers on top of our ResNet (as we've done in the past with our VGG models) and finetune for cats and dogs: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_fc_layers(p):\n",
    "    return [\n",
    "        BatchNormalization(axis=1, input_shape=rn0.output_shape[1:]),\n",
    "        Flatten(),\n",
    "        Dropout(p),\n",
    "        Dense(1024, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p/2),\n",
    "        Dense(1024, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p),\n",
    "        Dense(2, activation='softmax')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "batchnormalization_1 (BatchNormal(None, 2048, 7, 7)    4096        batchnormalization_input_1[0][0] \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 100352)        0           batchnormalization_1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 100352)        0           flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 1024)          102761472   dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_2 (BatchNormal(None, 1024)          2048        dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 1024)          0           batchnormalization_2[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 1024)          1049600     dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_3 (BatchNormal(None, 1024)          2048        dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 1024)          0           batchnormalization_3[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 2)             2050        dropout_3[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 103821314\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(get_fc_layers(0.5))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23000 samples, validate on 2000 samples\n",
      "Epoch 1/2\n",
      "23000/23000 [==============================] - 46s - loss: 0.1031 - acc: 0.9729 - val_loss: 0.0409 - val_acc: 0.9860\n",
      "Epoch 2/2\n",
      "23000/23000 [==============================] - 46s - loss: 0.0260 - acc: 0.9919 - val_loss: 0.0461 - val_acc: 0.9830\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe435911550>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trn_features, trn_labels, nb_epoch=2, batch_size=batch_size, validation_data=(val_features, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In just 92 seconds, our model has been able to achieve a validation accuracy of 98.4%, which would've ranked pretty high on the competition's leaderboard. As a comparison, my [kaggle submission](https://github.com/fdaham/fastai/blob/master/dogs_cats_kaggle.ipynb) using the VGG16 model achieved an accuracy of 98.5% and would've gotten 347/1314 on the leaderboard. \n",
    "\n",
    "## Other CNN Architectures\n",
    "\n",
    "### The Nature Conservancy Fisheries Monitoring Kaggle Competition \n",
    "\n",
    "More CNN architectures are used and discussed in [my submission](https://github.com/fdaham/fastai/blob/master/fisheries_kaggle.ipynb) of [the Nature Conservancy Fisheries Monitoring Kaggle Competition](https://www.kaggle.com/c/the-nature-conservancy-fisheries-monitoring/). The notebook covers the following architectures:\n",
    "\n",
    "* Data Leakage\n",
    "* Bounding Boxes\n",
    "* Multi-Output Models\n",
    "* Fully Convolutional Networks\n",
    "* Heatmaps\n",
    "* Inception CNNs\n",
    "* Psuedolabeling\n",
    "* Global Average Pooling\n",
    "\n",
    "This notebook is the last we'll discuss of CNNs for this part of the course. For the remainder of the lesson, we will review what we know about RNNs and build a more complicated RNN called the GRU.\n",
    "\n",
    "## Reviewing RNNs\n",
    "\n",
    "In [Lesson 6](https://github.com/fdaham/fastai/blob/master/lesson6.ipynb), we built an RNN in Theano, but hadn't yet explored the mechanics of how the gradients were being calculated as we allowed Theano to handle all of that for us. For educational purposes, we'll be covering the subject in this lesson as we build an RNN in pure python using NumPy. But, why are we doing this for an RNN? Well, RNNs handle the more difficult cases of backpropagation. If the mechanics are understood here, they'll be easier to understand in simpler cases elsewhere, like when dealing with CNNs.\n",
    "\n",
    "### Building an RNN in Pure Python \n",
    "\n",
    "Let's begin by creating the functions needed to calculate the Sigmoid and ReLU activations as well as the functions used to calculate their gradients (all functions ending with `_d`). Here's a simple derivation of the sigmoid derivative function:\n",
    "\n",
    "\\begin{equation*}\n",
    "sig(x) = \\frac{1}{1 + e^{-x}} \\to \\frac{1}{sig(x)} = 1 + e^{-x}\n",
    "\\end{equation*}\n",
    "\\begin{equation*}\n",
    "\\frac{d}{dx}\\frac{1}{sig(x)} = \\frac{-\\frac{d}{dx}sig(x)}{sig(x)^{2}} , \\frac{d}{dx}(1+e^{-x}) = -e^{-x} = 1 - \\frac{1}{sig(x)} = \\frac{sig(x) - 1}{sig(x)}\n",
    "\\end{equation*}\n",
    "\\begin{equation*}\n",
    "\\frac{-\\frac{d}{dx}sig(x)}{sig(x)^{2}} = \\frac{sig(x) - 1}{sig(x)} \\to \\frac{d}{dx}sig(x) = sig(x)(1-sig(x))\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x): return 1/(1+np.exp(-x))\n",
    "def sigmoid_d(x): \n",
    "    output = sigmoid(x)\n",
    "    return output*(1-output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ReLU, the function is defined as $f(x) = max(0, x)$, or: \n",
    "\n",
    "$$\n",
    "f(x) = \\left\\{\n",
    "        \\begin{array}{ll}\n",
    "            x, & \\quad x > 0 \\\\\n",
    "            0, & \\quad otherwise\n",
    "        \\end{array}\n",
    "    \\right.\n",
    "$$\n",
    "\n",
    "The piece-wise derivatives of the function are $f'(x > 0) = 1$ and $f'(x < 0) = 0$. The derivative $f'(x=0)$ is undefined and set to be 0.\n",
    "\n",
    "$$\n",
    "f'(x) = \\left\\{\n",
    "        \\begin{array}{ll}\n",
    "            1, & \\quad x > 0 \\\\\n",
    "            0, & \\quad otherwise\n",
    "        \\end{array}\n",
    "    \\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relu(x): return np.maximum(0., x)\n",
    "def relu_d(x): return (x > 0.)*1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same is done for the Euclidean distance function $f(a,b) = (a-b)^{2}$, with the simple derivative $f'(a,b) = 2(a-b)$..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dist(a,b): return pow(a-b,2)\n",
    "def dist_d(a,b): return 2*(a-b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...as well as for cross-entropy and softmax activation functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eps = 1e-7\n",
    "def x_entropy(pred, actual): \n",
    "    return -np.sum(actual * np.log(np.clip(pred, eps, 1-eps)))\n",
    "def x_entropy_d(pred, actual): return -actual/pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(x): return np.exp(x)/np.exp(x).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax_d(x):\n",
    "    sm = softmax(x)\n",
    "    res = np.expand_dims(-sm,-1)*sm\n",
    "    res[np.diag_indices_from(res)] = sm*(1-sm)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also need to define our own scan function, which will allow us to walk through and apply a function to each element of a sequence one step at a time. Since we're not worrying about parallelization, this should be very simple to implement. At each time step, we'll pass the next element of the sequence as the parameters to the function as well as the result from the previous run.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scan(fn, start, seq):\n",
    "    res = []\n",
    "    prev = start\n",
    "    for s in seq:\n",
    "        app = fn(prev, s)\n",
    "        res.append(app)\n",
    "        prev = app\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now going to train our RNN on the Nietzsche corpus with one-hot encoding. To start, we'll need to download the collected works of Nietzsche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 600901\n"
     ]
    }
   ],
   "source": [
    "path = get_file('nietzsche.txt', origin=\"https://s3.amazonaws.com/text-datasets/nietzsche.txt\")\n",
    "text = open(path).read()\n",
    "print('corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 86\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)+1\n",
    "print('total chars:', vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also do what we've done before in [Lesson 6](https://github.com/fdaham/fastai/blob/master/lesson6.ipynb) to initialize the appropriate variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# map chars to indices then back to chars\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert all chars to their index based on mapping above\n",
    "idx = [char_indices[c] for c in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create inputs\n",
    "cs = 8\n",
    "c_in_dat = [[idx[i+n] for i in xrange(0, len(idx)-1-cs, cs)]\n",
    "            for n in range(cs)]\n",
    "c_out_dat = [[idx[i+n] for i in xrange(1, len(idx)-cs, cs)]\n",
    "            for n in range(cs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xs = [np.stack(c[:-2]) for c in c_in_dat]\n",
    "ys = [np.stack(c[:-2]) for c in c_out_dat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "oh_xs = [to_categorical(o, vocab_size) for o in xs]\n",
    "oh_x_rnn = np.stack(oh_xs, axis=1)\n",
    "oh_ys = [to_categorical(o, vocab_size) for o in ys]\n",
    "oh_y_rnn=np.stack(oh_ys, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's define our data and shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((75110, 8, 86), (75110, 8, 86))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = oh_x_rnn\n",
    "outp = oh_y_rnn\n",
    "n_input = vocab_size\n",
    "n_output = vocab_size\n",
    "# get shape\n",
    "inp.shape, outp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can define our forward and backward pass functions. The forward pass will be pretty similar to our simple Theano RNN, but the backward pass will be a little different. Initially, we will do a forward pass of each character in the corpus by applying the function appropriately. The function that returns the hidden state after a single forward pass of the RNN for a single character is defined below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_char(prev, item):\n",
    "    # previous state\n",
    "    tot_loss, pre_hidden, pre_pred, hidden, ypred = prev\n",
    "    # current inputs and output\n",
    "    x, y = item\n",
    "    pre_hidden = np.dot(x,w_x) + np.dot(hidden,w_h)\n",
    "    hidden = act(pre_hidden)\n",
    "    pre_pred = np.dot(hidden,w_y)\n",
    "    ypred = softmax(pre_pred)\n",
    "    return (tot_loss+loss(ypred, y), pre_hidden, pre_pred, hidden, ypred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the hidden state, we'll need to apply the input weight matrix to $x$ and the hidden weight matrix to the previous hidden state, then add them element-wise before passing them through our activation. We'll then need to generate a prediction using the new hidden state with the output weight matrix and pass the resulting output through the softmax activation. \n",
    "\n",
    "Our function will keep track of the total loss by adding our current calculated loss to the previous loss for these predictions and labels. In addition, we'll also keep track of the weight matrices for backpropagation (`pre_hidden` and `pre_pred`), the new hidden state (`hidden`) for the next forward pass, and our predictions (`ypred`).  \n",
    "\n",
    "Then, we'll apply the scan function to the above for a sequence of characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_chars(n): return zip(inp[n], outp[n])\n",
    "def one_fwd(n): return scan(one_char, (0,0,0,np.zeros(n_hidden),0), get_chars(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the backward pass, we'll need to find the partial derivative of the output with respect to the input. This will let us know at what rate changing our input effects our output. We can use the diagram below to visualize this: \n",
    "\n",
    "![img](https://i.imgur.com/ADkWm0p.png[/img])\n",
    "\n",
    "Our final output, the last activation layer, is combined with our total loss, or the cumulative sum of each of the losses from the characters at each activation layer. If we want the derivative of the loss with respect to the derivative of the hidden activation, we would have to take the derivative of the loss with respect to the output activation and multiply it with the derivative of the hidden activation. \n",
    "\n",
    "We'll start with one of our inputs and one of our outputs, then go backwards through each of the characters in our sequence. The derivative of the loss will take us from the loss to the final output activation. The derivative of the softmax will get us from the output to the hidden layer through the other side of the activation function (the connecting blue arrow). \n",
    "\n",
    "To apply this process throughout the entire network, we'll use the chain rule to loop through every element of the sequence, iteratively applying the partial derivatives at each step using a learning rate (`alpha`) and accumulating the gradients across the sequence. The idea here is that we're trying to reverse all of the transformations and activation functions done in the forward pass. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# \"columnify\" a vector\n",
    "def col(x): return x[:,newaxis]\n",
    "\n",
    "def one_bkwd(args, n):\n",
    "    global w_x,w_y,w_h\n",
    "\n",
    "    i=inp[n]  # 8x86\n",
    "    o=outp[n] # 8x86\n",
    "    d_pre_hidden = np.zeros(n_hidden) # 256\n",
    "    for p in reversed(range(len(i))):\n",
    "        totloss, pre_hidden, pre_pred, hidden, ypred = args[p]\n",
    "        x=i[p] # 86\n",
    "        y=o[p] # 86\n",
    "        d_pre_pred = softmax_d(pre_pred).dot(loss_d(ypred,y))  # 86\n",
    "        d_pre_hidden = (np.dot(d_pre_hidden, w_h.T) \n",
    "                        + np.dot(d_pre_pred,w_y.T)) * act_d(pre_hidden) # 256\n",
    "\n",
    "        # outputs - d(loss)/d(w_y) = d(loss)/d(pre_pred) * d(pre_pred)/d(w_y)\n",
    "        w_y -= col(hidden) * d_pre_pred * alpha\n",
    "        # hiddens - d(loss)/d(w_h) = d(loss)/d(pre_hidden[p-1]) * d(pre_hidden[p-1])/d(w_h)\n",
    "        if (p>0): w_h -= args[p-1][3].dot(d_pre_hidden) * alpha\n",
    "        w_x -= col(x)*d_pre_hidden * alpha\n",
    "    return d_pre_hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll initialize our weight matrices as we would normally. To keep this example as simple as possible, we won't include bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_hidden, n_fac, cs, vocab_size = (256, 42, 8, 86)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scale = math.sqrt(2./n_input)\n",
    "w_x = normal(scale=scale, size=(n_input, n_hidden))\n",
    "w_y = normal(scale=scale, size=(n_hidden, n_output))\n",
    "w_h = np.eye(n_hidden, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our forward and backward steps have been defined and our weight matrices have been initialized, we can loop through our dataset and train our network: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((75110, 8, 86), (75110, 8, 86))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = oh_x_rnn\n",
    "Y = oh_y_rnn\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "act = relu\n",
    "act_d = relu_d\n",
    "loss = x_entropy\n",
    "loss_d = x_entropy_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:36.0060; Gradient:2.91292\n",
      "Error:35.2746; Gradient:4.00893\n",
      "Error:33.3053; Gradient:4.00392\n",
      "Error:30.9275; Gradient:3.23169\n",
      "Error:29.5900; Gradient:3.95175\n",
      "Error:29.3541; Gradient:3.53137\n",
      "Error:28.5532; Gradient:3.95373\n",
      "Error:28.0482; Gradient:3.43233\n",
      "Error:27.7101; Gradient:3.87015\n",
      "Error:27.6855; Gradient:2.81146\n"
     ]
    }
   ],
   "source": [
    "overallError = 0\n",
    "alpha = 0.0001\n",
    "for n in range(10000):\n",
    "    res = one_fwd(n)\n",
    "    overallError += res[-1][0]\n",
    "    deriv = one_bkwd(res, n)\n",
    "    if(n % 1000 == 999):\n",
    "        print (\"Error:{:.4f}; Gradient:{:.5f}\".format(\n",
    "                overallError/1000, np.linalg.norm(deriv)))\n",
    "        overallError = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Success! We can see that our network is minimizing the loss function after each step.\n",
    "\n",
    "Let's move on to more complex RNNs...\n",
    "\n",
    "\n",
    "## Advanced RNNs\n",
    "\n",
    "We briefly mentioned LSTMs in [Lesson 5](https://github.com/fdaham/fastai/blob/master/lesson5.ipynb). We won't have time to talk about LSTMs as we'll be finishing off this last lesson of part 1 of the course by discussing **GRUs**, or Gated Recurrent Units. Both techniques are used when building RNNs and are meant to prevent gradient explosions. However, GRUs are much simpler to implement than LSTMs.\n",
    "\n",
    "![img](https://i.imgur.com/6IAMUhR.png[/img])\n",
    "\n",
    "### The GRU\n",
    "\n",
    "In the diagram of the GRU above, we see an input is fed through a hidden state $h$ to produce an output. This logic seems normal, but what happens within the hidden state is what makes the GRU unique to a simple RNN. The hidden state updates itself by going through a weight matrix and activation function after passing through a reset gate $r$, which is like a mini neural network. The gate outputs some number between 0 and 1 and multiplies it with the input. This allows the network to either forget or remember the hidden state. \n",
    "\n",
    "How should we know whether or not we want to remember or forget the hidden state? We don't. That's why we have the neural network, which will learn a set of weights to decide when to forget what it knows. For all nonzero entries, the reset gate will reach the new value of the hidden state $\\tilde{h}$ after being reset. This then goes back to the top bit to meet the old hidden state with another gate, the update gate $z$ (another mini neural network). This gate decides how much of each state it will keep. If the value of the gate is 1, then the update will come purely from the previous hidden state. If it's 0, it will come purely from $\\tilde{h}$. Otherwise, it'll be determined again by another neural network.\n",
    "\n",
    "This is all already implemented in Theano. The Theano GRU looks just like the simple Theano RNN except for the use of the reset and update gates. We'll need separate weights for not just our input, hidden, and output, but also for our reset and update gates: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wgts_and_bias(n_in, n_out): \n",
    "    return init_wgts(n_in, n_out), init_bias(n_out)\n",
    "def id_and_bias(n): \n",
    "    return shared(np.eye(n, dtype=np.float32)), init_bias(n)\n",
    "def init_bias(rows): \n",
    "    return shared(np.zeros(rows, dtype=np.float32))\n",
    "def init_wgts(rows, cols): \n",
    "    scale = math.sqrt(2/rows)\n",
    "    return shared(normal(scale=scale, size=(rows, cols)).astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W_h = id_and_bias(n_hidden)\n",
    "W_x = init_wgts(n_input, n_hidden)\n",
    "W_y = wgts_and_bias(n_hidden, n_output)\n",
    "rW_h = init_wgts(n_hidden, n_hidden)\n",
    "rW_x = wgts_and_bias(n_input, n_hidden)\n",
    "uW_h = init_wgts(n_hidden, n_hidden)\n",
    "uW_x = wgts_and_bias(n_input, n_hidden)\n",
    "w_all = list(chain.from_iterable([W_h, W_y, uW_x, rW_x]))\n",
    "w_all.extend([W_x, uW_h, rW_h])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now define our gates, which will just be a sigmoid applied to the addition of the dot products of the input vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gate(x, h, W_h, W_x, b_x):\n",
    "    return nnet.sigmoid(T.dot(x, W_x) + b_x + T.dot(h, W_h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our step function will be nearly identical to what we've used before except that we'll multiply our hidden state by our reset gate before updating our hidden state based on the update gate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def step(x, h, W_h, b_h, W_y, b_y, uW_x, ub_x, rW_x, rb_x, W_x, uW_h, rW_h):\n",
    "    reset = gate(x, h, rW_h, rW_x, rb_x)\n",
    "    update = gate(x, h, uW_h, uW_x, ub_x)\n",
    "    h_new = gate(x, h * reset, W_h, W_x, b_h)\n",
    "    h = update*h + (1-update)*h_new\n",
    "    y = nnet.softmax(T.dot(h, W_y) + b_y)\n",
    "    return h, T.flatten(y, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've now intialized the weights for the respective gates and implemented the gates into our hidden loop. The great thing about GRUs is their ability to learn from the weights whether or not they should throw away or keep a hidden state. These extra degrees of freedom allow SGD to yield better results. \n",
    "\n",
    "Everything from here on is identical to our simple Theano RNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_inp = T.matrix('inp')\n",
    "t_outp = T.matrix('outp')\n",
    "t_h0 = T.vector('h0')\n",
    "lr = T.scalar('lr')\n",
    "all_args = [t_h0, t_inp, t_outp, lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[v_h, v_y], _ = theano.scan(step, sequences = t_inp, outputs_info = [t_h0, None], non_sequences = w_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "error = nnet.categorical_crossentropy(v_y, t_outp).sum()\n",
    "g_all = T.grad(error, w_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def upd_dict(wgts, grads, lr): \n",
    "    return OrderedDict({w: w-g*lr for (w,g) in zip(wgts,grads)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "upd = upd_dict(w_all, g_all, lr)\n",
    "fn = theano.function(all_args, error, updates=upd, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:21.27\n",
      "Error:18.61\n",
      "Error:17.59\n",
      "Error:17.45\n",
      "Error:16.88\n",
      "Error:16.33\n",
      "Error:16.02\n"
     ]
    }
   ],
   "source": [
    "err = 0.0; l_rate = 0.1\n",
    "for i in range(len(X)): \n",
    "    err+=fn(np.zeros(n_hidden), X[i], Y[i], l_rate)\n",
    "    if i % 10000 == 9999: \n",
    "        l_rate *= 0.95\n",
    "        print (\"Error:{:.2f}\".format(err/10000))\n",
    "        err=0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now combine the weights. To make things simpler and faster, we'll concatenate the hidden and input matrices together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = (shared(np.concatenate([np.eye(n_hidden), normal(size=(n_input, n_hidden))])\n",
    "            .astype(np.float32)), init_bias(n_hidden))\n",
    "rW = wgts_and_bias(n_input+n_hidden, n_hidden)\n",
    "uW = wgts_and_bias(n_input+n_hidden, n_hidden)\n",
    "W_y = wgts_and_bias(n_hidden, n_output)\n",
    "w_all = list(chain.from_iterable([W, W_y, uW, rW]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gate(m, W, b): return nnet.sigmoid(T.dot(m, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def step(x, h, W, b, W_y, b_y, uW, ub, rW, rb):\n",
    "    m = T.concatenate([h, x])\n",
    "    reset = gate(m, rW, rb)\n",
    "    update = gate(m, uW, ub)\n",
    "    m = T.concatenate([h*reset, x])\n",
    "    h_new = gate(m, W, b)\n",
    "    h = update*h + (1-update)*h_new\n",
    "    y = nnet.softmax(T.dot(h, W_y) + b_y)\n",
    "    return h, T.flatten(y, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[v_h, v_y], _ = theano.scan(step, sequences=t_inp, \n",
    "                            outputs_info=[t_h0, None], non_sequences=w_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def upd_dict(wgts, grads, lr): \n",
    "    return OrderedDict({w: w-g*lr for (w,g) in zip(wgts,grads)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "error = nnet.categorical_crossentropy(v_y, t_outp).sum()\n",
    "g_all = T.grad(error, w_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "upd = upd_dict(w_all, g_all, lr)\n",
    "fn = theano.function(all_args, error, updates=upd, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:21.29\n",
      "Error:19.51\n",
      "Error:18.51\n",
      "Error:18.24\n",
      "Error:17.72\n",
      "Error:17.05\n",
      "Error:16.66\n"
     ]
    }
   ],
   "source": [
    "err=0.0; l_rate=0.01\n",
    "for i in range(len(X)): \n",
    "    err+=fn(np.zeros(n_hidden), X[i], Y[i], l_rate)\n",
    "    if i % 10000 == 9999: \n",
    "        print (\"Error:{:.2f}\".format(err/10000))\n",
    "        err=0.0"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
